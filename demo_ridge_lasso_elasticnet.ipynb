{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "demo_ridge_lasso_elasticnet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOYhlfDWKycvEkv2RkYs5q/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/afit-csce623-master/demos/blob/main/demo_ridge_lasso_elasticnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51jGVasovC4n"
      },
      "source": [
        "# This tutorial developed by W. Blair Watkinson II\n",
        "# Apr 30, 2021\n",
        "\n",
        "# Developed in support of education and research activities at \n",
        "# the Air Force Institute of Technology and the CSCE 623\n",
        "# Machine Learning course\n",
        "\n",
        "# For changes or questions, contact warren.watkinson@afit.edu\n",
        "\n",
        "# Public Domain\n",
        "\n",
        "# This is free and unencumbered software released into the public domain.\n",
        "\n",
        "# Anyone is free to copy, modify, publish, use, compile, sell, or\n",
        "# distribute this software, either in source code form or as a compiled\n",
        "# binary, for any purpose, commercial or non-commercial, and by any\n",
        "# means.\n",
        "\n",
        "# In jurisdictions that recognize copyright laws, the author or authors\n",
        "# of this software dedicate any and all copyright interest in the\n",
        "# software to the public domain. We make this dedication for the benefit\n",
        "# of the public at large and to the detriment of our heirs and\n",
        "# successors. We intend this dedication to be an overt act of\n",
        "# relinquishment in perpetuity of all present and future rights to this\n",
        "# software under copyright law.\n",
        "\n",
        "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\n",
        "# EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n",
        "# MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.\n",
        "# IN NO EVENT SHALL THE AUTHORS BE LIABLE FOR ANY CLAIM, DAMAGES OR\n",
        "# OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,\n",
        "# ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR\n",
        "# OTHER DEALINGS IN THE SOFTWARE.\n",
        "\n",
        "# For more information, please refer to <https://unlicense.org>"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RqRv7gnYXNHF"
      },
      "source": [
        "# Ridge, Lasso, and ElasticNet Demo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JUcs5fH98-Lu"
      },
      "source": [
        "This notebook demonstrates the use of Ridge, Lasso, and ElasticNet on a linear regression dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q8dnwK5nXSr2"
      },
      "source": [
        "## Generate Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ykyhqHJ-xYc"
      },
      "source": [
        "Here we generate regression data with 8 features, but only 3 features are needed to determine the target `y`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O3XoZQtRM6hl"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import make_regression\n",
        "import time\n",
        "\n",
        "from IPython.display import Markdown as md\n",
        "from IPython.display import display, Math, Latex\n",
        "\n",
        "# initialize random state and regression parameters\n",
        "random_state = np.random.RandomState(101)\n",
        "n_features = 8\n",
        "n_informative = 3\n",
        "bias_data = random_state.uniform(0,10)\n",
        "noise = 2\n",
        "\n",
        "# Build a regression task\n",
        "X, y, coef_data = make_regression(n_samples=6000, \n",
        "                                  n_features=n_features, n_informative=n_informative, \n",
        "                                  bias=bias_data, noise=noise,\n",
        "                                  random_state=random_state, coef=True)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ATRKQBA3XUkd"
      },
      "source": [
        "## Helper Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQJREDcY-52E"
      },
      "source": [
        "The following helper functions will be used throughout this tutorial."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cz4DvDr2Xhw8"
      },
      "source": [
        "### Generate Model Function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wffxOZIE-9SL"
      },
      "source": [
        "This function generates a model string of the form $y = \\beta_0 + \\beta_1 x_1 + \\dots + \\beta_n x_n$ where $n$ is the number of coefficients in `betas`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOZbGERCOnlE"
      },
      "source": [
        "def generate_model_function(beta0, betas, feature_names):\n",
        "    if np.isclose(beta0, 0):\n",
        "        model_function = f'$y = '\n",
        "    else:\n",
        "        model_function = f'$y = {beta0:.3f} + '\n",
        "\n",
        "    for beta, feature_name in zip(betas, feature_names):\n",
        "        model_function += f'{beta:.3f}{feature_name} + '\n",
        "    \n",
        "    return model_function[:-3] + '$'"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_GIccjVpXlli"
      },
      "source": [
        "### Clean Up Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "taJNjfp7_bMA"
      },
      "source": [
        "Some models don't clean-up very small coefficients, leaving values looking like $ \\dots + 0.000 x_3 + \\dots $. This function will filter out coefficients that are near zero."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBC7nnL4Qg6R"
      },
      "source": [
        "def clean_up_model(coefs, names):\n",
        "    non_zero_coef_filter = np.logical_not(np.isclose(coefs, 0))\n",
        "    non_zero_coefs = coefs[non_zero_coef_filter]\n",
        "    non_zero_names = names[non_zero_coef_filter]\n",
        "\n",
        "    return non_zero_coefs, non_zero_names\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4j8f2or6Xp5T"
      },
      "source": [
        "### Generate Clean Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BbcGUnDb_y7n"
      },
      "source": [
        "This function combines the above two functions to return a cleaned-up model string."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jNEoRvPhf1EL"
      },
      "source": [
        "def generate_clean_model(beta0, coefs, names):\n",
        "    coefs_, names_ = clean_up_model(coefs, names)\n",
        "    return generate_model_function(beta0, coefs_, names_)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ato9lwsaXs-_"
      },
      "source": [
        "### Powerset Function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RarJVNi1_27H"
      },
      "source": [
        "This function generates the power set of a list, excluding the empty set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dMnCU3E2rmQw"
      },
      "source": [
        "# powerset function\n",
        "\n",
        "from itertools import chain, combinations\n",
        "\n",
        "def powerset(iterable, j=1, k=999):\n",
        "    \"powerset([1,2,3]) --> () (1,) (2,) (3,) (1,2) (1,3) (2,3) (1,2,3)\"\n",
        "    s = list(iterable)\n",
        "\n",
        "    # start with 1, as we don't need the empty set\n",
        "    p = list(chain.from_iterable(combinations(s, r) for r in range(1, len(s)+1)))\n",
        "    return [item for item in p if len(item) >= j and len(item) <= k]\n",
        "\n",
        "feature_powerset = powerset(range(n_features))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ETAw-RhgbIqN"
      },
      "source": [
        "### Time String"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4qgmHLi_bL3C"
      },
      "source": [
        "def convert_to_time(seconds):\n",
        "    return time.strftime('%H:%M:%S', time.gmtime(seconds))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00omhviges2K"
      },
      "source": [
        "### Progress String"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0SAwp5yoeu_I"
      },
      "source": [
        "def print_progress_str(start_time, trial_time, total_trials, current_trial_idx, feature_set_name_str, best_score, current_score):\n",
        "\n",
        "    time_elapsed_str = convert_to_time(time.perf_counter() - start_time)\n",
        "    time_trial_sec = time.perf_counter() - trial_time\n",
        "\n",
        "    status_str = f'{time_elapsed_str} {time_trial_sec:.2f}s {current_trial_idx} of {total_trials}: {feature_set_name_str} {current_score}'\n",
        "    remaining_time = (time.perf_counter() - start_time) / current_trial_idx * (total_trials - current_trial_idx)\n",
        "    \n",
        "    if (current_score < best_score):\n",
        "        print('\\r', status_str)\n",
        "    else:\n",
        "        print('\\r', status_str, f'Time Remaining: {time.strftime(\"%H:%M:%S\", time.gmtime(remaining_time))}', end='')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5tmXjkZyAAqn"
      },
      "source": [
        "## Prepatory actons"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k6OBz3oiAIma"
      },
      "source": [
        "Here, we split the train and test datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WuphFhLhNZfd"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# split and sequester test data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=random_state)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HTjhNsAWAOMM"
      },
      "source": [
        "We set some variables that we will reuse throught the notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JoEsu_RLNRgt"
      },
      "source": [
        "kfold_size = 5\n",
        "\n",
        "# create feature names -- these are generic feature names x_1, x_2, ..., x_25\n",
        "feature_names = np.array([f'x_{{{idx+1}}}' for idx in range(n_features)])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58IQ3r_9TExT"
      },
      "source": [
        "## Ridge"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2mYuY_ayYxpo"
      },
      "source": [
        "### Set alpha values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aclnC-OAIum5"
      },
      "source": [
        "We will set alpha values. With Ridge regression, we will include 0.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QvJ5dcFJYzD3"
      },
      "source": [
        "alpha_min = 0.0000001\n",
        "alpha_max = 100000\n",
        "alpha_num = int(abs(np.log10(alpha_min)) + abs(np.log10(alpha_max)) + 1)\n",
        "alphas = np.geomspace(alpha_min, alpha_max, num=alpha_num)\n",
        "alphas = np.insert(alphas, 0, 0)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kCrdAxa0Yhry"
      },
      "source": [
        "### Ridge - manual cross validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qk2x6oTDI46y"
      },
      "source": [
        "The following code uses the Ridge regression model for each alpha value. We keep track of each RMSE, and select the model that yielded the lowest RMSE. We compare the model with the model that generated the original dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        },
        "id": "ObNmaKPxWQBs",
        "outputId": "fe2a99a9-c000-4e1e-abe3-e09ce9462b3c"
      },
      "source": [
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "df_ridge = pd.DataFrame(columns=['alpha', 'rmse', 'r2'])\n",
        "\n",
        "for alpha in alphas:\n",
        "    ridge = Ridge(alpha=alpha, fit_intercept=True, random_state=random_state)\n",
        "    scores = cross_val_score(ridge, X_train, y_train, scoring='neg_root_mean_squared_error', cv=kfold_size)\n",
        "    ridge.fit(X_train, y_train)\n",
        "    df_ridge.loc[len(df_ridge.index)] = [alpha, -np.mean(scores), ridge.score(X_test, y_test)]\n",
        "\n",
        "best_ridge = {}\n",
        "best_ridge['alpha'] = df_ridge.loc[np.argmin(df_ridge['rmse'])]['alpha']\n",
        "best_ridge['model'] = Ridge(alpha=best_ridge['alpha'], fit_intercept=True, random_state=random_state)\n",
        "best_ridge['model'].fit(X_train, y_train)\n",
        "best_ridge['r2'] = best_ridge['model'].score(X_test, y_test)\n",
        "y_pred = best_ridge['model'].predict(X_test)\n",
        "best_ridge['rmse'] = mean_squared_error(y_test, y_pred, squared=False)\n",
        "\n",
        "display(md(f'Best Ridge with $\\\\alpha$={best_ridge[\"alpha\"]}: ' +\n",
        "           f'{(generate_clean_model(best_ridge[\"model\"].intercept_, best_ridge[\"model\"].coef_, feature_names))}, ' +\n",
        "           f'RMSE: {best_ridge[\"rmse\"]:.4f}, $R^2$: {best_ridge[\"r2\"]:.4f}'))\n",
        "display(md(f'Original Data: {(generate_clean_model(bias_data, coef_data, feature_names))}'))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "Best Ridge with $\\alpha$=0.0: $y = 5.190 + 0.004x_{1} + 39.521x_{2} + -0.001x_{3} + 16.122x_{4} + 34.609x_{5} + 0.015x_{6} + -0.001x_{7} + -0.023x_{8}$, RMSE: 2.0544, $R^2$: 0.9987",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "Original Data: $y = 5.164 + 39.530x_{2} + 16.115x_{4} + 34.584x_{5}$",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vdQgNT4wYlDo"
      },
      "source": [
        "### RidgeCV"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p0CclZFwJNKV"
      },
      "source": [
        "The following code uses the RidgeCV to automatically find the alpha value that yields the smallest RMSE. We compare the model with the model that generated the original dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 94
        },
        "id": "bWx9570fYm-E",
        "outputId": "06d5a895-9b24-4889-9c4a-e93b0661f294"
      },
      "source": [
        "from sklearn.linear_model import RidgeCV\n",
        "\n",
        "ridgeCV = RidgeCV(alphas=alphas,\n",
        "                  scoring='neg_root_mean_squared_error',\n",
        "                  cv=kfold_size)\n",
        "ridgeCV.fit(X_train, y_train)\n",
        "ridgeCV_r2 = ridgeCV.score(X_test, y_test)\n",
        "y_pred = ridgeCV.predict(X_test)\n",
        "ridgeCV_rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
        "display(md(f'RidgeCV with $\\\\alpha$={ridgeCV.alpha_}: ' +\n",
        "           f'{(generate_clean_model(ridgeCV.intercept_, ridgeCV.coef_, feature_names))}, ' +\n",
        "           f'RMSE: {ridgeCV_rmse:.4f}, $R^2$: {ridgeCV_r2:.4f}'))\n",
        "display(md(f'Original Data: {(generate_clean_model(bias_data, coef_data, feature_names))}'))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "RidgeCV with $\\alpha$=0.0: $y = 5.190 + 0.004x_{1} + 39.521x_{2} + -0.001x_{3} + 16.122x_{4} + 34.609x_{5} + 0.015x_{6} + -0.001x_{7} + -0.023x_{8}$, RMSE: 2.0544, $R^2$: 0.9987",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "Original Data: $y = 5.164 + 39.530x_{2} + 16.115x_{4} + 34.584x_{5}$",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OGVfIW4ubks2"
      },
      "source": [
        "### Ridge with subsets of features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N75D307tJWaR"
      },
      "source": [
        "Neither Ridge nor RidgeCV is able to fully eliminate unimportant features. Here, we test the power set of features to find the set of features and alpha value that generates the lowest RMSE."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 655
        },
        "id": "eiP13kfDbnF_",
        "outputId": "5538d710-aad6-4585-fb40-f041ae660313"
      },
      "source": [
        "# use power set\n",
        "\n",
        "df_ridge = pd.DataFrame(columns=['feature_set', 'alpha', 'rmse']) #, 'r2'])\n",
        "\n",
        "trial_time = time.perf_counter()\n",
        "start_time = time.perf_counter()\n",
        "total_trials = len(feature_powerset) * len(alphas)\n",
        "current_trial_idx = 0\n",
        "best_rmse = 1000\n",
        "\n",
        "for idx_feature, feature_set in enumerate(feature_powerset):\n",
        "\n",
        "    feature_set_str = ','.join(str(e) for e in feature_set) # current feature set as string\n",
        "    feature_set_name_str = ','.join(str(e) for e in feature_names[np.array(feature_set)]) # feature set names as string\n",
        "\n",
        "    for idx_alpha, alpha in enumerate(alphas):\n",
        "        current_trial_idx += 1\n",
        "\n",
        "        ridge = Ridge(alpha=alpha, fit_intercept=True, random_state=random_state)\n",
        "        scores = cross_val_score(ridge, X_train[:,np.array(feature_set)], y_train, scoring='neg_root_mean_squared_error', cv=kfold_size)\n",
        "\n",
        "        # store details in dataframe for later accessing\n",
        "        df_ridge.loc[len(df_ridge.index)] = [feature_set_str, alpha, -np.mean(scores)]\n",
        "\n",
        "        # print to show progress\n",
        "        print_progress_str(start_time, trial_time, total_trials, current_trial_idx, feature_set_name_str, best_rmse, -np.mean(scores))\n",
        "\n",
        "        # update best_rmse\n",
        "        best_rmse = -np.mean(scores) if -np.mean(scores) < best_rmse else best_rmse\n",
        "\n",
        "        trial_time = time.perf_counter()\n",
        "\n",
        "print('\\r', f'Total time: {convert_to_time(time.perf_counter() - start_time)}')\n",
        "\n",
        "best_ridge = {}\n",
        "best_ridge['params'] = df_ridge.loc[np.argmin(df_ridge['rmse'])]\n",
        "best_ridge['features'] = [int(e) for e in best_ridge['params']['feature_set'].split(',')]\n",
        "best_ridge['feature_names'] = feature_names[np.array(best_ridge['features'])]\n",
        "best_ridge['alpha'] = best_ridge['params']['alpha']\n",
        "\n",
        "best_ridge['model'] = Ridge(alpha=best_ridge['alpha'])\n",
        "best_ridge['model'].fit(X_train[:,np.array(best_ridge['features'])], y_train)\n",
        "best_ridge['r2'] = best_ridge['model'].score(X_test[:,np.array(best_ridge['features'])], y_test)\n",
        "y_pred = best_ridge['model'].predict(X_test[:,np.array(best_ridge['features'])])\n",
        "best_ridge['rmse'] = mean_squared_error(y_test, y_pred, squared=False)\n",
        "\n",
        "display(md(f'Best Ridge with $\\\\alpha$={best_ridge[\"alpha\"]}: ' +\n",
        "           f'{(generate_clean_model(best_ridge[\"model\"].intercept_, best_ridge[\"model\"].coef_, best_ridge[\"feature_names\"]))}, ' + \n",
        "           f'RMSE: {best_ridge[\"rmse\"]:.4f}, ' +\n",
        "           f'$R^2$: {best_ridge[\"r2\"]:.4f}'\n",
        "           ))\n",
        "display(md(f'Original Data: {(generate_clean_model(bias_data, coef_data, feature_names))}'))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r 00:00:00 0.02s 0 of 3570: x_{1} 54.94646561692082\n",
            "\r 00:00:00 0.02s 0 of 3570: x_{1} 54.94646561692032\n",
            "\r 00:00:00 0.02s 0 of 3570: x_{1} 54.94646561691578\n",
            "\r 00:00:00 0.02s 0 of 3570: x_{1} 54.946465616870434\n",
            "\r 00:00:00 0.01s 0 of 3570: x_{1} 54.946465616417015\n",
            "\r 00:00:00 0.02s 0 of 3570: x_{1} 54.94646561188281\n",
            "\r 00:00:00 0.01s 0 of 3570: x_{1} 54.946465566540816\n",
            "\r 00:00:00 0.01s 0 of 3570: x_{1} 54.94646511313441\n",
            "\r 00:00:00 0.02s 0 of 3570: x_{1} 54.94646058042177\n",
            "\r 00:00:00 0.01s 0 of 3570: x_{1} 54.946415388038226\n",
            "\r 00:00:00 0.01s 0 of 3570: x_{1} 54.945976550772755\n",
            "\r 00:00:00 0.01s 0 of 3570: x_{1} 54.94259711361771\n",
            " 00:00:00 0.01s 0 of 3570: x_{1} 54.93404193564304\n",
            " 00:00:00 0.01s 0 of 3570: x_{1} 54.93058194410062\n",
            " 00:00:00 0.02s 1 of 3570: x_{2} 38.54805627120733\n",
            " 00:00:03 0.02s 15 of 3570: x_{2},x_{3} 38.54774111644366\n",
            " 00:00:03 0.02s 15 of 3570: x_{2},x_{3} 38.547741116443504\n",
            " 00:00:03 0.02s 15 of 3570: x_{2},x_{3} 38.5477411164421\n",
            " 00:00:03 0.02s 15 of 3570: x_{2},x_{3} 38.54774111642805\n",
            " 00:00:03 0.02s 15 of 3570: x_{2},x_{3} 38.54774111628759\n",
            " 00:00:03 0.01s 15 of 3570: x_{2},x_{3} 38.547741114884346\n",
            " 00:00:03 0.02s 15 of 3570: x_{2},x_{3} 38.54774110098103\n",
            " 00:00:03 0.02s 15 of 3570: x_{2},x_{3} 38.5477409748637\n",
            " 00:00:03 0.02s 16 of 3570: x_{2},x_{4} 35.017649838485895\n",
            " 00:00:04 0.02s 17 of 3570: x_{2},x_{5} 16.23822825411947\n",
            " 00:00:04 0.02s 17 of 3570: x_{2},x_{5} 16.238228254119342\n",
            " 00:00:04 0.02s 17 of 3570: x_{2},x_{5} 16.238228254118162\n",
            " 00:00:04 0.02s 17 of 3570: x_{2},x_{5} 16.23822825410634\n",
            " 00:00:04 0.02s 17 of 3570: x_{2},x_{5} 16.23822825398816\n",
            " 00:00:04 0.02s 17 of 3570: x_{2},x_{5} 16.23822825281151\n",
            " 00:00:04 0.02s 17 of 3570: x_{2},x_{5} 16.23822824155293\n",
            " 00:00:04 0.02s 17 of 3570: x_{2},x_{5} 16.238228179762224\n",
            " 00:00:18 0.03s 62 of 3570: x_{2},x_{4},x_{5} 1.9564495954860015\n",
            " Total time: 00:01:28\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "Best Ridge with $\\alpha$=0.0: $y = 5.190 + 39.521x_{2} + 16.122x_{4} + 34.609x_{5}$, RMSE: 2.0540, $R^2$: 0.9987",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "Original Data: $y = 5.164 + 39.530x_{2} + 16.115x_{4} + 34.584x_{5}$",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81tbIKecZErl"
      },
      "source": [
        "## Lasso"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qihdwBP9ZHV_"
      },
      "source": [
        "### Set alpha values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JjTE1niELOI_"
      },
      "source": [
        "We will set alpha values. With Lasso regression, we will not include 0."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1fltmQvKZWBl"
      },
      "source": [
        "alpha_min = 0.0000001\n",
        "alpha_max = 100000\n",
        "alpha_num = int(abs(np.log10(alpha_min)) + abs(np.log10(alpha_max)) + 1)\n",
        "alphas = np.geomspace(alpha_min, alpha_max, num=alpha_num)\n",
        "\n",
        "# Lasso is unreliable with alpha=0, use LinearRegression instead when alpha=0 is desired\n",
        "#alphas = np.insert(alphas, 0, 0)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LFgXQuwfZLlm"
      },
      "source": [
        "### Lasso - manual cross validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C0gTkM7iLSl-"
      },
      "source": [
        "The following code uses the Lasso regression model for each alpha value. We keep track of each RMSE, and select the model that yielded the lowest RMSE. We compare the model with the model that generated the original dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 77
        },
        "id": "jka9W-bxZf-V",
        "outputId": "4e2384a7-5397-4275-958e-e911341238d1"
      },
      "source": [
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "df_lasso = pd.DataFrame(columns=['alpha', 'rmse', 'r2'])\n",
        "\n",
        "for alpha in alphas:\n",
        "    lasso = Lasso(alpha=alpha, fit_intercept=True, random_state=random_state)\n",
        "    scores = cross_val_score(lasso, X_train, y_train, scoring='neg_root_mean_squared_error', cv=kfold_size)\n",
        "    lasso.fit(X_train, y_train)\n",
        "    df_lasso.loc[len(df_lasso.index)] = [alpha, -np.mean(scores), lasso.score(X_test, y_test)]\n",
        "\n",
        "best_lasso = {}\n",
        "best_lasso['alpha'] = df_lasso.loc[np.argmin(df_lasso['rmse'])]['alpha']\n",
        "best_lasso['model'] = Lasso(alpha=best_lasso['alpha'], fit_intercept=True, random_state=random_state)\n",
        "best_lasso['model'].fit(X_train, y_train)\n",
        "best_lasso['r2'] = best_lasso['model'].score(X_test, y_test)\n",
        "y_pred = best_lasso['model'].predict(X_test)\n",
        "best_lasso['rmse'] = mean_squared_error(y_test, y_pred, squared=False)\n",
        "\n",
        "display(md(f'Best Ridge with $\\\\alpha$={best_lasso[\"alpha\"]}: ' +\n",
        "           f'{(generate_clean_model(best_lasso[\"model\"].intercept_, best_lasso[\"model\"].coef_, feature_names))}, ' +\n",
        "           f'RMSE: {best_lasso[\"rmse\"]:.4f}, $R^2$: {best_lasso[\"r2\"]:.4f}'))\n",
        "display(md(f'Original Data: {(generate_clean_model(bias_data, coef_data, feature_names))}'))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "Best Ridge with $\\alpha$=0.01: $y = 5.190 + 39.511x_{2} + 16.112x_{4} + 34.599x_{5} + 0.005x_{6} + -0.012x_{8}$, RMSE: 2.0544, $R^2$: 0.9987",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "Original Data: $y = 5.164 + 39.530x_{2} + 16.115x_{4} + 34.584x_{5}$",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UwVSU7dEZOhF"
      },
      "source": [
        "### LassoCV"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMVm5z1SLYwY"
      },
      "source": [
        "The following code uses the LassoCV to automatically find the alpha value that yields the smallest RMSE. We compare the model with the model that generated the original dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 77
        },
        "id": "-UP8k_u3ZGWE",
        "outputId": "dce772a7-e4c7-4599-e3f1-2ffc7d3d4595"
      },
      "source": [
        "from sklearn.linear_model import LassoCV\n",
        "\n",
        "lassoCV = LassoCV(alphas=alphas,\n",
        "                #   scoring='neg_root_mean_squared_error',\n",
        "                  cv=kfold_size)\n",
        "lassoCV.fit(X_train, y_train)\n",
        "lassoCV_r2 = lassoCV.score(X_test, y_test)\n",
        "y_pred = lassoCV.predict(X_test)\n",
        "lassoCV_rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
        "display(md(f'LassoCV with $\\\\alpha$={lassoCV.alpha_}: ' +\n",
        "           f'{(generate_clean_model(lassoCV.intercept_, lassoCV.coef_, feature_names))}, ' +\n",
        "           f'RMSE: {lassoCV_rmse:.4f}, $R^2$: {lassoCV_r2:.4f}'))\n",
        "display(md(f'Original Data: {(generate_clean_model(bias_data, coef_data, feature_names))}'))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "LassoCV with $\\alpha$=0.01: $y = 5.190 + 39.511x_{2} + 16.112x_{4} + 34.599x_{5} + 0.005x_{6} + -0.012x_{8}$, RMSE: 2.0544, $R^2$: 0.9987",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "Original Data: $y = 5.164 + 39.530x_{2} + 16.115x_{4} + 34.584x_{5}$",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZobiGFXhcIVi"
      },
      "source": [
        "### Lasso with subsets of features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qnkfxZvPLnGd"
      },
      "source": [
        "Though it performs better than Ridge, neither Lasso nor LassoCV is able to fully eliminate unimportant features. Here, we test the power set of features to find the set of features and alpha value that generates the lowest RMSE."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "RG91g4QsDrdl",
        "outputId": "5426c18e-18b2-4b96-f119-6d2e34cc2bdf"
      },
      "source": [
        "# use power set\n",
        "\n",
        "df_lasso = pd.DataFrame(columns=['feature_set', 'alpha', 'rmse'])\n",
        "\n",
        "trial_time = time.perf_counter()\n",
        "start_time = time.perf_counter()\n",
        "total_trials = len(feature_powerset) * len(alphas)\n",
        "current_trial_idx = 0\n",
        "best_rmse = 1000\n",
        "\n",
        "for feature_set in feature_powerset:\n",
        "\n",
        "    feature_set_str = ','.join(str(e) for e in feature_set) # current feature set as string\n",
        "    feature_set_name_str = ','.join(str(e) for e in feature_names[np.array(feature_set)]) # feature set names as string\n",
        "\n",
        "    for alpha in alphas:\n",
        "        current_trial_idx += 1\n",
        "\n",
        "        lasso = Lasso(alpha=alpha, fit_intercept=True, random_state=random_state)\n",
        "        scores = cross_val_score(lasso, X_train[:,np.array(feature_set)], y_train, scoring='neg_root_mean_squared_error', cv=kfold_size)\n",
        "\n",
        "        # store details in dataframe for later accessing\n",
        "        df_lasso.loc[len(df_lasso.index)] = [feature_set_str, alpha, -np.mean(scores)]\n",
        "\n",
        "        # print to show progress\n",
        "        print_progress_str(start_time, trial_time, total_trials, current_trial_idx, feature_set_name_str, best_rmse, -np.mean(scores))\n",
        "\n",
        "        # update best_rmse\n",
        "        best_rmse = -np.mean(scores) if -np.mean(scores) < best_rmse else best_rmse\n",
        "\n",
        "        trial_time = time.perf_counter()\n",
        "\n",
        "print('\\r', f'Total time: {convert_to_time(time.perf_counter() - start_time)}')\n",
        "\n",
        "best_lasso = {}\n",
        "best_lasso['params'] = df_lasso.loc[np.argmin(df_lasso['rmse'])]\n",
        "best_lasso['features'] = [int(e) for e in best_lasso['params']['feature_set'].split(',')]\n",
        "best_lasso['feature_names'] = feature_names[np.array(best_lasso['features'])]\n",
        "best_lasso['alpha'] = best_lasso['params']['alpha']\n",
        "\n",
        "best_lasso['model'] = Lasso(alpha=best_lasso['alpha'])\n",
        "best_lasso['model'].fit(X_train[:,np.array(best_lasso['features'])], y_train)\n",
        "best_lasso['r2'] = best_lasso['model'].score(X_test[:,np.array(best_lasso['features'])], y_test)\n",
        "y_pred = best_lasso['model'].predict(X_test[:,np.array(best_lasso['features'])])\n",
        "best_lasso['rmse'] = mean_squared_error(y_test, y_pred, squared=False)\n",
        "\n",
        "display(md(f'Best Lasso with $\\\\alpha$={best_lasso[\"alpha\"]}: ' +\n",
        "           f'{(generate_clean_model(best_lasso[\"model\"].intercept_, best_lasso[\"model\"].coef_, best_lasso[\"feature_names\"]))}, ' + \n",
        "           f'RMSE: {best_lasso[\"rmse\"]:.4f}, ' +\n",
        "           f'$R^2$: {best_lasso[\"r2\"]:.4f}'\n",
        "           ))\n",
        "display(md(f'Original Data: {(generate_clean_model(bias_data, coef_data, feature_names))}'))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r 00:00:00 0.02s 254 of 3315: x_{1} 54.94646561320748\n",
            "\r 00:00:00 0.01s 254 of 3315: x_{1} 54.94646557978742\n",
            "\r 00:00:00 0.02s 254 of 3315: x_{1} 54.9464652455877\n",
            "\r 00:00:00 0.01s 254 of 3315: x_{1} 54.94646190367321\n",
            "\r 00:00:00 0.01s 254 of 3315: x_{1} 54.94642849280281\n",
            "\r 00:00:00 0.02s 254 of 3315: x_{1} 54.946095211563076\n",
            "\r 00:00:00 0.01s 254 of 3315: x_{1} 54.94284515107049\n",
            " 00:00:00 0.02s 254 of 3315: x_{1} 54.9300791092254\n",
            " 00:00:00 0.02s 254 of 3315: x_{2} 38.54805627128544\n",
            " 00:00:03 0.02s 254 of 3315: x_{2},x_{3} 38.54774111642003\n",
            " 00:00:03 0.02s 254 of 3315: x_{2},x_{3} 38.547741116268114\n",
            " 00:00:03 0.02s 254 of 3315: x_{2},x_{3} 38.54774111381802\n",
            " 00:00:03 0.02s 254 of 3315: x_{2},x_{3} 38.54774109526809\n",
            " 00:00:03 0.02s 254 of 3315: x_{2},x_{3} 38.54774093409294\n",
            " 00:00:03 0.01s 254 of 3315: x_{2},x_{4} 35.01764983856283\n",
            " 00:00:03 0.02s 254 of 3315: x_{2},x_{5} 16.238228254325243\n",
            " 00:00:16 0.02s 254 of 3315: x_{2},x_{4},x_{5} 1.95644959553184\n",
            " 00:00:16 0.02s 254 of 3315: x_{2},x_{4},x_{5} 1.9564495936140438\n",
            " 00:00:16 0.02s 254 of 3315: x_{2},x_{4},x_{5} 1.9564495716849464\n",
            " Total time: 80.62s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "Best Lasso with $\\alpha$=1e-05: $y = 5.190 + 39.521x_{2} + 16.122x_{4} + 34.609x_{5}$, RMSE: 2.0540, $R^2$: 0.9987",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "Original Data: $y = 5.164 + 39.530x_{2} + 16.115x_{4} + 34.584x_{5}$",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U7zE5eoVeDzX"
      },
      "source": [
        "## ElasticNet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1b6kgVtaeaLT"
      },
      "source": [
        "### Set alpha values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qNeSzHUTLw4I"
      },
      "source": [
        "We will set alpha values. With ElasticNet regression, which includes Lasso when l1_ratio=1, we will not include 0."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3nUnghLXeb7e"
      },
      "source": [
        "alpha_min = 0.0000001\n",
        "alpha_max = 100000\n",
        "alpha_num = int(abs(np.log10(alpha_min)) + abs(np.log10(alpha_max)) + 1)\n",
        "alphas = np.geomspace(alpha_min, alpha_max, num=alpha_num)\n",
        "\n",
        "# Lasso is unreliable with alpha=0, use LinearRegression instead when alpha=0 is desired\n",
        "#alphas = np.insert(alphas, 0, 0)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BU6kNhXwekAb"
      },
      "source": [
        "### Set lr_ratio values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vuDJQsPhME9R"
      },
      "source": [
        "Set l1_ratio values. This is that amount of l1 regularization the linear model will attempt to perform (l1_ratio = 1.0 corresponds with Lasso, and l1_ratio = 0.0 corresponds with Ridge)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XyT63444eGle"
      },
      "source": [
        "l1_ratios = np.linspace(0.01, 1.0 ,num=100)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ztjUcEvjwTx"
      },
      "source": [
        "### ElasticNetCV"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VlK4GqaGMDh2"
      },
      "source": [
        "The following code uses the ElasticNetCV to automatically find the alpha and l1_ratio values that yield the smallest RMSE. We compare the model with the model that generated the original dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 77
        },
        "id": "K7nDCe_Vf29r",
        "outputId": "4bcabe94-c32a-477b-f0c5-51a4f2ebabf8"
      },
      "source": [
        "from sklearn.linear_model import ElasticNetCV\n",
        "\n",
        "elastic_netCV = ElasticNetCV(alphas=alphas,\n",
        "                      l1_ratio = l1_ratios,\n",
        "                #   scoring='neg_root_mean_squared_error',\n",
        "                  cv=kfold_size,\n",
        "                  max_iter=1000)\n",
        "elastic_netCV.fit(X_train, y_train)\n",
        "elastic_netCV_r2 = elastic_netCV.score(X_test, y_test)\n",
        "y_pred = elastic_netCV.predict(X_test)\n",
        "elastic_netCV_rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
        "display(md(f'ElasticCV with $\\\\alpha$={elastic_netCV.alpha_}, $l1$ ratio={elastic_netCV.l1_ratio_}: ' +\n",
        "           f'{(generate_clean_model(elastic_netCV.intercept_, elastic_netCV.coef_, feature_names))}, ' +\n",
        "           f'RMSE: {elastic_netCV_rmse:.4f}, $R^2$: {elastic_netCV_r2:.4f}'))\n",
        "display(md(f'Original Data: {(generate_clean_model(bias_data, coef_data, feature_names))}'))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "ElasticCV with $\\alpha$=0.01, $l1$ ratio=1.0: $y = 5.190 + 39.511x_{2} + 16.112x_{4} + 34.599x_{5} + 0.005x_{6} + -0.012x_{8}$, RMSE: 2.0544, $R^2$: 0.9987",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "Original Data: $y = 5.164 + 39.530x_{2} + 16.115x_{4} + 34.584x_{5}$",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQ_mQ0KvjzUf"
      },
      "source": [
        "### ElasticNet with subsets of features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qir406pFMsQ5"
      },
      "source": [
        "ElasticNetCV's performance in this case is nearly identical to that of Lasso.Here, we test the power set of features to find the set of features, alpha, and l1_ratio values that generate the lowest RMSE."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x4FMmp1Sj25p",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        },
        "outputId": "b688e83e-0ba0-4eed-b9fc-a50f8f9d8cbb"
      },
      "source": [
        "# use power set\n",
        "\n",
        "from sklearn.linear_model import ElasticNet\n",
        "\n",
        "df_elastic_net = pd.DataFrame(columns=['feature_set', 'alpha', 'rmse'])\n",
        "\n",
        "trial_time = time.perf_counter()\n",
        "start_time = time.perf_counter()\n",
        "total_trials = len(feature_powerset) * len(alphas) * len(l1_ratios)\n",
        "current_trial_idx = 0\n",
        "best_rmse = 1000\n",
        "\n",
        "for feature_set in feature_powerset:\n",
        "\n",
        "    feature_set_str = ','.join(str(e) for e in feature_set) # current feature set as string\n",
        "    feature_set_name_str = ','.join(str(e) for e in feature_names[np.array(feature_set)]) # feature set names as string\n",
        "\n",
        "    for alpha in alphas:\n",
        "        for l1_ratio in l1_ratios:\n",
        "            current_trial_idx += 1\n",
        "\n",
        "            # create model\n",
        "            elastic_net = ElasticNet(alpha=alpha, fit_intercept=True, random_state=random_state)\n",
        "\n",
        "            # calculate rmse scores\n",
        "            scores = cross_val_score(elastic_net, X_train[:,np.array(feature_set)], y_train, scoring='neg_root_mean_squared_error', cv=kfold_size)\n",
        "\n",
        "            # store details in dataframe for later accessing\n",
        "            df_elastic_net.loc[len(df_elastic_net.index)] = [feature_set_str, alpha, -np.mean(scores)]\n",
        "\n",
        "            # print to show progress\n",
        "            print_progress_str(start_time, trial_time, total_trials, current_trial_idx, feature_set_name_str, best_rmse, -np.mean(scores))\n",
        "\n",
        "            # update best_rmse\n",
        "            best_rmse = -np.mean(scores) if -np.mean(scores) < best_rmse else best_rmse\n",
        "\n",
        "            trial_time = time.perf_counter()\n",
        "\n",
        "print('\\r', f'Total time: {convert_to_time(time.perf_counter() - start_time)}')\n",
        "\n",
        "best_elastic_net = {}\n",
        "best_elastic_net['params'] = df_elastic_net.loc[np.argmin(df_elastic_net['rmse'])]\n",
        "best_elastic_net['features'] = [int(e) for e in best_elastic_net['params']['feature_set'].split(',')]\n",
        "best_elastic_net['feature_names'] = feature_names[np.array(best_elastic_net['features'])]\n",
        "best_elastic_net['alpha'] = best_elastic_net['params']['alpha']\n",
        "\n",
        "best_elastic_net['model'] = ElasticNet(alpha=best_elastic_net['alpha'])\n",
        "best_elastic_net['model'].fit(X_train[:,np.array(best_elastic_net['features'])], y_train)\n",
        "best_elastic_net['r2'] = best_elastic_net['model'].score(X_test[:,np.array(best_elastic_net['features'])], y_test)\n",
        "y_pred = best_elastic_net['model'].predict(X_test[:,np.array(best_elastic_net['features'])])\n",
        "best_elastic_net['rmse'] = mean_squared_error(y_test, y_pred, squared=False)\n",
        "\n",
        "display(md(f'Best ElasticNet with $\\\\alpha$={best_elastic_net[\"alpha\"]}, $l1$ ratio={elastic_netCV.l1_ratio_}: ' +\n",
        "           f'{(generate_clean_model(best_elastic_net[\"model\"].intercept_, best_elastic_net[\"model\"].coef_, best_elastic_net[\"feature_names\"]))}, ' + \n",
        "           f'RMSE: {best_elastic_net[\"rmse\"]:.4f}, ' +\n",
        "           f'$R^2$: {best_elastic_net[\"r2\"]:.4f}'\n",
        "           ))\n",
        "display(md(f'Original Data: {(generate_clean_model(bias_data, coef_data, feature_names))}'))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 00:00:00 0.02s 254 of 331500: x_{1} 54.94646561409685\n",
            " 00:00:01 0.01s 254 of 331500: x_{1} 54.94646558868114\n",
            " 00:00:03 0.01s 254 of 331500: x_{1} 54.94646533452584\n",
            " 00:00:04 0.02s 254 of 331500: x_{1} 54.94646279314649\n",
            " 00:00:06 0.01s 254 of 331500: x_{1} 54.94643739671174\n",
            " 00:00:08 0.01s 254 of 331500: x_{1} 54.94618515717078\n",
            " 00:00:09 0.01s 254 of 331500: x_{1} 54.94382481191995\n",
            " 00:00:11 0.02s 254 of 331500: x_{1} 54.933119653278126\n",
            " 00:00:13 0.01s 254 of 331500: x_{1} 54.9300791092254\n",
            " 00:00:21 0.01s 254 of 331500: x_{2} 38.54805627222929\n",
            " 00:05:33 0.01s 254 of 331500: x_{2},x_{3} 38.54774111613717\n",
            " 00:05:35 0.02s 254 of 331500: x_{2},x_{3} 38.54774111338162\n",
            " 00:05:37 0.02s 254 of 331500: x_{2},x_{3} 38.54774108545722\n",
            " 00:05:38 0.01s 254 of 331500: x_{2},x_{3} 38.5477408620678\n",
            " 00:05:56 0.02s 254 of 331500: x_{2},x_{4} 35.017649839097416\n",
            " 00:06:19 0.02s 254 of 331500: x_{2},x_{5} 16.23822825406914\n",
            " 00:06:21 0.02s 254 of 331500: x_{2},x_{5} 16.238228252019876\n",
            " 00:06:23 0.02s 254 of 331500: x_{2},x_{5} 16.2382282318817\n",
            " 00:06:25 0.02s 254 of 331500: x_{2},x_{5} 16.23822822796064\n",
            " 00:31:07 0.03s 254 of 331500: x_{2},x_{4},x_{5} 1.9564495975521257\n",
            " Total time: 11601.97s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "Best ElasticNet with $\\alpha$=1e-07, $l1$ ratio=1.0: $y = 5.190 + 39.521x_{2} + 16.122x_{4} + 34.609x_{5}$, RMSE: 2.0540, $R^2$: 0.9987",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "Original Data: $y = 5.164 + 39.530x_{2} + 16.115x_{4} + 34.584x_{5}$",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}